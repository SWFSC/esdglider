{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sample-misc\n",
    "\n",
    "A sample notebook for miscellaneous code and experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda deactivate && conda env update --file glider-utils/environment.yml --prune\n",
    "# from subprocess import run\n",
    "# run([\"/home/sam_woodman_noaa_gov/glider-utils/resources/sync-cache.sh\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fusermount: failed to unmount /home/sam_woodman_noaa_gov/amlr-gliders-deployments-dev: Device or resource busy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"timestamp\":{\"seconds\":1744301001,\"nanos\":615517759},\"severity\":\"INFO\",\"message\":\"Start gcsfuse/2.5.1 (Go version go1.23.0) for app \\\"\\\" using mount point: /home/sam_woodman_noaa_gov/amlr-gliders-deployments-dev\\n\"}\n",
      "{\"timestamp\":{\"seconds\":1744301001,\"nanos\":615555469},\"severity\":\"INFO\",\"message\":\"GCSFuse config\",\"config\":{\"AppName\":\"\",\"CacheDir\":\"\",\"Debug\":{\"ExitOnInvariantViolation\":false,\"Fuse\":false,\"Gcs\":false,\"LogMutex\":false},\"EnableHns\":true,\"FileCache\":{\"CacheFileForRangeRead\":false,\"DownloadChunkSizeMb\":50,\"EnableCrc\":false,\"EnableODirect\":false,\"EnableParallelDownloads\":false,\"MaxParallelDownloads\":16,\"MaxSizeMb\":-1,\"ParallelDownloadsPerFile\":16,\"WriteBufferSize\":4194304},\"FileSystem\":{\"DirMode\":\"755\",\"DisableParallelDirops\":false,\"FileMode\":\"644\",\"FuseOptions\":[],\"Gid\":-1,\"IgnoreInterrupts\":true,\"KernelListCacheTtlSecs\":0,\"RenameDirLimit\":0,\"TempDir\":\"\",\"Uid\":-1},\"Foreground\":false,\"GcsAuth\":{\"AnonymousAccess\":false,\"KeyFile\":\"\",\"ReuseTokenFromUrl\":true,\"TokenUrl\":\"\"},\"GcsConnection\":{\"BillingProject\":\"\",\"ClientProtocol\":\"http1\",\"CustomEndpoint\":\"\",\"ExperimentalEnableJsonRead\":false,\"GrpcConnPoolSize\":1,\"HttpClientTimeout\":0,\"LimitBytesPerSec\":-1,\"LimitOpsPerSec\":-1,\"MaxConnsPerHost\":0,\"MaxIdleConnsPerHost\":100,\"SequentialReadSizeMb\":200},\"GcsRetries\":{\"MaxRetryAttempts\":0,\"MaxRetrySleep\":30000000000,\"Multiplier\":2},\"ImplicitDirs\":true,\"List\":{\"EnableEmptyManagedFolders\":false},\"Logging\":{\"FilePath\":\"\",\"Format\":\"json\",\"LogRotate\":{\"BackupFileCount\":10,\"Compress\":true,\"MaxFileSizeMb\":512},\"Severity\":\"INFO\"},\"MetadataCache\":{\"DeprecatedStatCacheCapacity\":20460,\"DeprecatedStatCacheTtl\":60000000000,\"DeprecatedTypeCacheTtl\":60000000000,\"EnableNonexistentTypeCache\":false,\"ExperimentalMetadataPrefetchOnMount\":\"disabled\",\"StatCacheMaxSizeMb\":32,\"TtlSecs\":60,\"TypeCacheMaxSizeMb\":4},\"Metrics\":{\"PrometheusPort\":0,\"StackdriverExportInterval\":0},\"Monitoring\":{\"ExperimentalOpentelemetryCollectorAddress\":\"\",\"ExperimentalTracingMode\":\"\",\"ExperimentalTracingSamplingRatio\":0},\"OnlyDir\":\"\",\"Write\":{\"CreateEmptyFile\":false}}}\n",
      "{\"timestamp\":{\"seconds\":1744301001,\"nanos\":795471030},\"severity\":\"INFO\",\"message\":\"2025/04/10 16:03:21.795447 Error occurred during command execution: daemonize.Run: readFromProcess: sub-process: Error while mounting gcsfuse: mountWithArgs: mountWithStorageHandle: mount: mount: running /usr/bin/fusermount: exit status 1\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error: daemonize.Run: readFromProcess: sub-process: Error while mounting gcsfuse: mountWithArgs: mountWithStorageHandle: mount: mount: running /usr/bin/fusermount: exit status 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyglider import slocum\n",
    "from pyglider import utils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from esdglider import glider, utils, gcp\n",
    "\n",
    "deployment = 'calanus-20241019'\n",
    "project = \"ECOSWIM\"\n",
    "mode = 'delayed'\n",
    "\n",
    "# deployment = 'amlr08-20220513'\n",
    "# project = \"SANDIEGO\"\n",
    "# mode = 'delayed'\n",
    "\n",
    "year = utils.year_path(project, deployment)\n",
    "bucket_name = 'amlr-gliders-deployments-dev'\n",
    "deployments_path = f\"/home/sam_woodman_noaa_gov/{bucket_name}\"\n",
    "config_path = f\"/home/sam_woodman_noaa_gov/glider-lab/deployment-configs\"\n",
    "\n",
    "gcp.gcs_mount_bucket(\n",
    "    \"amlr-gliders-deployments-dev\", deployments_path, \n",
    "    ro=False)\n",
    "\n",
    "paths = glider.get_path_deployment(\n",
    "    project, deployment, mode, deployments_path, config_path)\n",
    "\n",
    "cacdir = paths[\"cacdir\"]\n",
    "binarydir = paths[\"binarydir\"]\n",
    "\n",
    "# dir_ts = paths[\"tsdir\"]\n",
    "# path_sci = os.path.join(dir_ts, f\"{deployment}-{mode}-sci.nc\")\n",
    "# path_eng = os.path.join(dir_ts, f\"{deployment}-{mode}-eng.nc\")\n",
    "\n",
    "# ds_eng = xr.load_dataset(path_eng)\n",
    "# ds_sci = xr.load_dataset(path_sci)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1ts_outname_sci = slocum.binary_to_timeseries(\n",
    "    binarydir, \n",
    "    cacdir, \n",
    "    \"/home/sam_woodman_noaa_gov\", \n",
    "    paths[\"deploymentyaml\"],\n",
    "    search='*.[D|E|d|e]bd', fnamesuffix='-sci',\n",
    "    time_base='sci_water_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1ts_outname_eng = slocum.binary_to_timeseries(\n",
    "    binarydir, cacdir, outdir, \n",
    "    [deploymentyaml, engyaml],\n",
    "    search='*.[D|E|d|e]bd', fnamesuffix='-eng',\n",
    "    # search='*.[D|E]BD', fnamesuffix='',\n",
    "    time_base='m_depth', profile_filt_time=100,\n",
    "    profile_min_time=300, maxgap=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_sci = xr.open_dataset(l1ts_outname_sci)\n",
    "# ts_oxy = xr.open_dataset(os.path.join(l1tsdir, f\"{deployment}-oxy.nc\"))\n",
    "ts_sci\n",
    "# list(ts_sci.data_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_eng = xr.open_dataset(l1ts_outname_eng)\n",
    "ts_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postproc_eng_timeseries(ts_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_eng.attrs[\"comment\"]\n",
    "print(not ts_eng.attrs[\"comment\"].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts_sci.close()\n",
    "# ts_oxy.close()\n",
    "# ts_eng.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dbdreader exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sam_woodman_noaa_gov/amlr-gliders-deployments-dev/ECOSWIM/2024/calanus-20241019/data/binary/delayed\n"
     ]
    }
   ],
   "source": [
    "import dbdreader\n",
    "print(binarydir)\n",
    "dbd = dbdreader.MultiDBD(\n",
    "    pattern=f'{binarydir}/{'*.[D|E|d|e]bd'}', cacheDir=cacdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sensors = [\"sci_water_temp\", \"m_depth\", \"m_pitch\", \"m_roll\", \"m_tot_num_inflections\"]\n",
    "sensors = ['m_lat', 'm_lon', 'm_depth', 'm_heading', 'm_pitch', 'm_roll', 'm_tot_num_inflections', 'c_wpt_lat', 'c_wpt_lon', 'sci_water_cond', 'sci_water_temp', 'sci_water_pressure', 'c_de_oil_vol', 'm_de_oil_vol', 'm_coulomb_amphr_total', 'm_coulomb_amphr', 'm_battery', 'm_vacuum', 'm_leakdetect_voltage', 'm_leakdetect_voltage_forward', 'm_leakdetect_voltage_science', 'm_battpos', 'c_dive_target_depth', 'm_altitude']\n",
    "data_list = [(t, v) for (t,v) in dbd.get(*sensors, return_nans=True)]\n",
    "data_time, data = zip(*data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = [\"m_depth\", \"m_heading\", \"m_pitch\", \"m_roll\", \"m_tot_num_inflections\"]\n",
    "t1, d = dbd.get(param_names[0], return_nans=True)\n",
    "t2, h = dbd.get(param_names[1], return_nans=True)\n",
    "t3, p = dbd.get(param_names[2], return_nans=True)\n",
    "t4, r = dbd.get(param_names[3], return_nans=True)\n",
    "t5, i = dbd.get(param_names[4], return_nans=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find where array1 is NaN\n",
    "nan_in_array1 = np.isnan(d)\n",
    "\n",
    "# Check if values in arrays 2-4 are NOT NaN at positions where array1 is NaN\n",
    "non_nan_in_arrays_2_to_4 = (~np.isnan(h) | ~np.isnan(p) | ~np.isnan(r)) & nan_in_array1\n",
    "\n",
    "# Indices where array1 is NaN and any of arrays 2-4 is not NaN\n",
    "indices = np.where(non_nan_in_arrays_2_to_4)[0]\n",
    "\n",
    "# Output the indices\n",
    "print(\"Indices where array1 is NaN and arrays 2-4 are not NaN:\", indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing times\n",
    "\n",
    "Main purpose of this section is to confirm that xarray.merge is doing what we expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = ts_sci.time.to_numpy()\n",
    "# t2 = ts_oxy.time.to_numpy()\n",
    "t3 = ts_eng.time.to_numpy()\n",
    "\n",
    "df_union = np.union1d(t1, t3)\n",
    "print(len(t1))\n",
    "print(len(t3))\n",
    "print(len(df_union))\n",
    "df_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_all = ['latitude', 'longitude', 'waypoint_latitude', 'waypoint_longitude']\n",
    "sci_vars = vars_all + ['conductivity', 'temperature', 'pressure',\n",
    "            'depth', 'salinity', 'potential_density', 'density', 'potential_temperature',\n",
    "            'profile_index', 'profile_direction']\n",
    "oxy_vars = vars_all + [\"oxygen_concentration\"]\n",
    "eng_vars = vars_all + [\"m_depth\", \"heading\", \"pitch\", \"roll\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_sci = ts_sci[sci_vars]\n",
    "ts_oxy = ts_oxy[oxy_vars]\n",
    "ts_eng = ts_eng[eng_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = xr.merge([ts_sci, ts_oxy, ts_eng], compat = \"no_conflicts\", \n",
    "              join  = \"outer\", combine_attrs = \"override\")\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# any(np.isnan(ts.latitude.values))\n",
    "# good = ~np.isnan(ts.latitude.values + ts.longitude.values)\n",
    "\n",
    "# print(np.nanmax(ts.latitude.values))\n",
    "# print(np.max(ts.latitude.values[good]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalculate attributes as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good = ~np.isnan(ts.latitude.values + ts.longitude.values)\n",
    "ts.attrs['geospatial_lat_max'] = np.nanmax(ts.latitude.values[good])\n",
    "ts.attrs['geospatial_lat_min'] = np.nanmin(ts.latitude.values[good])\n",
    "ts.attrs['geospatial_lon_max'] = np.nanmax(ts.longitude.values[good])\n",
    "ts.attrs['geospatial_lon_min'] = np.nanmin(ts.longitude.values[good])\n",
    "ts.attrs['geospatial_lat_units'] = 'degrees_north'\n",
    "ts.attrs['geospatial_lon_units'] = 'degrees_east'\n",
    "\n",
    "dt = ts.time.values\n",
    "ts.attrs['time_coverage_start'] = '%s' % dt[0]\n",
    "ts.attrs['time_coverage_end'] = '%s' % dt[-1]\n",
    "\n",
    "ts.attrs['deployment_start'] = str(dt[0].astype('datetime64[s]'))\n",
    "ts.attrs['deployment_end'] = str(dt[-1].astype('datetime64[s]'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalculate profile values as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth_good = np.where(~np.isnan(ts.m_depth))[0]\n",
    "ts.m_depth.values = np.interp(np.arange(len(ts.m_depth)), good, ts.m_depth.values[good])\n",
    "ts = get_profiles_esd(ts, \"m_depth\")\n",
    "\n",
    "# tg_ind = utils.find_gaps(ts.time.values[depth_good], ts.time.values, 300)\n",
    "# np.where(tg_ind)\n",
    "# dep = ts.m_depth.to_pandas()\n",
    "\n",
    "ts = utils.get_distance_over_ground(ts)\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outname = os.path.join(l1tsdir, f\"{deployment}-union.nc\")\n",
    "ts.to_netcdf(outname, 'w',\n",
    "             encoding={'time': {'units': 'seconds since 1970-01-01T00:00:00Z',\n",
    "                                '_FillValue': np.nan,\n",
    "                                'dtype': 'float64'}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xarray selecting - ffill and bfill\n",
    "\n",
    "Exploring the various 'method' arguments for xarray's sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# da = xr.DataArray([1, 2, 3], [(\"x\", [0, 1, 2])])\n",
    "# display(da)\n",
    "\n",
    "da = xr.DataArray(\n",
    "    # np.random.rand(4),\n",
    "    [1, 2, 3, 4], \n",
    "    [\n",
    "        (\"time\", pd.date_range(\"2000-01-01\", periods=4)),\n",
    "        # (\"space\", [\"IA\", \"IL\", \"IN\"]),\n",
    "    ],\n",
    ")\n",
    "# display(da)\n",
    "ds = da.to_dataset(name=\"foo\")\n",
    "display(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.sel(time=[\"2000-01-01 12:00:00\"],method = 'bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da.sel(x=[0.5, 1, 1.5, 2], method=\"bfill\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esdglider",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
