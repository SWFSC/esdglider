{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import math\n",
    "\n",
    "import esdglider.gcp as gcp\n",
    "import esdglider.glider as glider\n",
    "import esdglider.utils as utils\n",
    "\n",
    "deployment_name = 'calanus-20241019' \n",
    "mode = 'delayed'\n",
    "\n",
    "year = utils.year_path(project, deployment)\n",
    "bucket_name = 'amlr-gliders-deployments-dev'\n",
    "deployments_path = f\"/home/sam_woodman_noaa_gov/{bucket_name}\"\n",
    "config_path = f\"/home/sam_woodman_noaa_gov/glider-lab/deployment-config\"\n",
    "\n",
    "gcp.gcs_mount_bucket(\n",
    "    \"amlr-gliders-deployments-dev\", deployments_path, \n",
    "    ro=False)\n",
    "\n",
    "deployment_info = {\n",
    "    \"deploymentyaml\": os.path.join(config_path, f\"{deployment_name}.yml\"), \n",
    "    \"mode\": mode, \n",
    "}\n",
    "paths = glider.get_path_glider(\n",
    "    deployment_info, deployments_path)\n",
    "\n",
    "dir_ts = paths[\"tsdir\"]\n",
    "path_raw = os.path.join(dir_ts, f\"{deployment_name}-{mode}-raw.nc\")\n",
    "path_sci = os.path.join(dir_ts, f\"{deployment_name}-{mode}-sci.nc\")\n",
    "path_eng = os.path.join(dir_ts, f\"{deployment_name}-{mode}-eng.nc\")\n",
    "\n",
    "dir_ngdac = paths[\"profdir\"]\n",
    "if os.path.isdir(dir_ngdac):\n",
    "    files_ngdac = os.listdir(dir_ngdac)\n",
    "# files_ngdac\n",
    "# os.path.join(paths[\"profdir\"], f\"{deployment} -{mode}.nc\")\n",
    "# path_sci = os.path.join(dir_ts, 'calanus-20241019-sci.nc')\n",
    "# path_eng = os.path.join(dir_ts, 'calanus-20241019-eng.nc')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sci = xr.load_dataset(path_sci)\n",
    "ds_sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_eng = xr.load_dataset(path_eng)\n",
    "ds_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import random\n",
    "from branca.colormap import linear\n",
    "\n",
    "# # Example dataset selection from xarray (replace with your own dataset)\n",
    "# ds = ds_eng #.sel(time=slice(\"2024-10-19\", \"2024-10-20\"))\n",
    "# print(f\"Number of points: {len(ds.time.values)}\")\n",
    "\n",
    "def folium_play(ds, sample_rate=10):\n",
    "    # Extract lat, lon, and info (datetime)\n",
    "    lat = ds[\"latitude\"].values\n",
    "    lon = ds[\"longitude\"].values\n",
    "    # info = np.datetime_as_string(ds[\"time\"].values, unit='s')\n",
    "    dates = ds[\"time\"].values  # The datetime values\n",
    "    \n",
    "    # Extract and concatenate info\n",
    "    time_str = np.datetime_as_string(ds[\"time\"].values, unit='s')\n",
    "    distance_str = ds[\"distance_over_ground\"].values.astype(str)\n",
    "    info = np.char.add(time_str, '\\n')\n",
    "    info = np.char.add(info, distance_str)\n",
    "\n",
    "    # Convert datetime to numerical values (e.g., Unix timestamp or days since a reference date)\n",
    "    start_date = np.datetime64(ds[\"time\"].values.min())\n",
    "    days_since_start = (dates - start_date).astype(int)  # Convert timedelta to integer days\n",
    "\n",
    "    # Create a base map, centered around the average lat/lon\n",
    "    m = folium.Map(\n",
    "        location=[np.mean(lat), np.mean(lon)], \n",
    "        zoom_start=10, \n",
    "        tiles=\"cartodb positron\"\n",
    "    )\n",
    "\n",
    "    # Define a color map for the date range\n",
    "    colormap = linear.YlGnBu_09.scale(min(days_since_start), max(days_since_start))  # Blue scale\n",
    "\n",
    "    # Downsampling the data for performance improvement (optional)\n",
    "    downsampled_indices = random.sample(range(len(lat)), len(lat) // sample_rate)  # Adjust sampling rate\n",
    "    lat_downsampled = lat[downsampled_indices]\n",
    "    lon_downsampled = lon[downsampled_indices]\n",
    "    info_downsampled = info[downsampled_indices]\n",
    "    days_since_start_downsampled = days_since_start[downsampled_indices]\n",
    "\n",
    "    print(len(lon_downsampled))\n",
    "\n",
    "    # Add CircleMarkers to the map, colored by the date\n",
    "    for i in range(len(lat_downsampled)):\n",
    "        # Map the datetime to a color\n",
    "        color = colormap(days_since_start_downsampled[i])\n",
    "\n",
    "        # Create a Tooltip with minimal information\n",
    "        tooltip = info_downsampled[i]  # Tooltip will show the date\n",
    "\n",
    "        # Create a CircleMarker with the calculated color\n",
    "        folium.CircleMarker(\n",
    "            location=[lat_downsampled[i], lon_downsampled[i]], \n",
    "            radius=3,  # Adjust the radius for better visibility\n",
    "            color=color, \n",
    "            fill=True, \n",
    "            fill_color=color,  # Use the same color for filling\n",
    "            fill_opacity=0.6,\n",
    "            tooltip=tooltip  # Use Tooltip instead of Popup\n",
    "        ).add_to(m)\n",
    "\n",
    "    # Add the colormap to the map for reference\n",
    "    colormap.add_to(m)\n",
    "\n",
    "    # Display the map\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_raw = xr.load_dataset(path_raw)\n",
    "ll_good = (\n",
    "        (ds_raw.longitude >= -180)\n",
    "        & (ds_raw.longitude <= 180)\n",
    "        & (ds_raw.latitude >= -90)\n",
    "        & (ds_raw.latitude <= 90))\n",
    "ds = ds_raw.where(ll_good, drop = True)\n",
    "mr = folium_play(ds)\n",
    "display(mr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "me = folium_play(ds_eng)\n",
    "display(me)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = folium_play(ds_sci)\n",
    "display(ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xarray as xr\n",
    "# import matplotlib.pyplot as plt\n",
    "# import cartopy.crs as ccrs\n",
    "# import cartopy.feature as cfeature\n",
    "\n",
    "# # Open the dataset (replace 'your_dataset.nc' with the path to your file)\n",
    "# # ds = xr.open_dataset('your_dataset.nc')\n",
    "\n",
    "# # Extract the latitude and longitude values\n",
    "# lat = ds_sci['latitude'].values  # Assuming 'lat' is the latitude dimension\n",
    "# lon = ds_sci['longitude'].values  # Assuming 'lon' is the longitude dimension\n",
    "\n",
    "# # Extract the data values you want to plot (let's assume it is called 'data')\n",
    "# data = ds_sci['temperature'].values  # This could be your variable of interest\n",
    "\n",
    "# # Set up the plot with Cartopy projection\n",
    "# fig, ax = plt.subplots(figsize=(10, 6), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "# # Plot the points on the map\n",
    "# scatter = ax.scatter(lon, lat, c=data, cmap='viridis', edgecolor='k', marker='o', s=20, transform=ccrs.PlateCarree())\n",
    "\n",
    "# # Add Cartopy features for a nice map appearance\n",
    "# ax.coastlines(resolution='10m')  # Draw coastlines with a medium resolution\n",
    "# ax.add_feature(cfeature.BORDERS, linestyle=':', linewidth=2)  # Add country borders\n",
    "# ax.add_feature(cfeature.LAND, edgecolor='black')  # Add land with black edges\n",
    "# ax.add_feature(cfeature.LAND, facecolor='lightgray')  # Land color\n",
    "# # ax.add_feature(cfeature.LAKE, facecolor='lightblue')  # Lakes in light blue\n",
    "# # ax.add_feature(cfeature.RIVERS)  # Add rivers\n",
    "\n",
    "# # Add gridlines for latitude and longitude\n",
    "# ax.gridlines(draw_labels=True, linewidth=1, color='gray', linestyle='--')\n",
    "\n",
    "# # Add a colorbar\n",
    "# cbar = plt.colorbar(scatter, ax=ax, orientation='vertical')\n",
    "# cbar.set_label('Data Value')\n",
    "\n",
    "# # Set a title\n",
    "# ax.set_title('Data Points on Map', fontsize=16)\n",
    "\n",
    "# # Show the plot\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sci.distance_over_ground.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_diff = ds_sci.distance_over_ground.values - np.roll(ds_sci.distance_over_ground.values, 1)\n",
    "# y_diff = y.distance_over_ground.values - np.roll(y.distance_over_ground.values, 1)\n",
    "display(pd.DataFrame(ds_diff).describe())\n",
    "\n",
    "np.argmax(ds_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_sci_grid5 = xr.load_dataset(os.path.join(paths[\"griddir\"], f\"{deployment}_grid-{mode}-5m.nc\"))\n",
    "# ds_sci_grid5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_prof0 = xr.load_dataset(os.path.join(dir_ngdac, files_ngdac[0]))\n",
    "# display(ds_prof0)\n",
    "\n",
    "# ds_prof20 = xr.load_dataset(os.path.join(dir_ngdac, files_ngdac[20]))\n",
    "# display(ds_prof20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_eng = ds_eng.to_pandas()\n",
    "pd_sci = ds_sci.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unifying profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = pd_eng.reset_index()\n",
    "# # x.profile_index = np.floor(x.profile_index)\n",
    "# y = x.groupby('profile_index').agg(\n",
    "#     time_start = ('time', 'min'), \n",
    "#     time_end = ('time', 'max'), \n",
    "#     depth_first = ('depth', 'first'), \n",
    "#     depth_last = ('depth', 'last')\n",
    "# )\n",
    "# # y.loc[:-1, \"time_end\"] = y['time_start'].shift(-1).iloc[:-1]\n",
    "\n",
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y2 = x.groupby('profile_index').agg(\n",
    "#     time_start = ('time', 'min')\n",
    "# ).reset_index()\n",
    "# print(y2)\n",
    "\n",
    "# z = pd_sci.drop('profile_index', axis=1)\n",
    "# d = pd.merge_asof(z, y2, left_index=True, right_on=\"time_start\", direction = \"backward\")\n",
    "# d[['depth', 'profile_index', 'profile_direction', 'time_start']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_eng2 = utils.get_profiles_esd(ds_eng, \"depth\")\n",
    "# pd_eng2 = ds_eng2.to_pandas()\n",
    "\n",
    "# prof_idx, prof_dir = utils.findProfiles(\n",
    "#     ds_eng2.time.values, ds_eng2.depth.values, stall=20, shake=200)\n",
    "# pd_eng2['prof_idx'] = prof_idx\n",
    "# pd_eng2['prof_dir'] = prof_dir\n",
    "\n",
    "# # 'latitude', 'longitude', \n",
    "# pd_eng2[['depth', 'profile_index',\n",
    "#         'profile_direction', 'prof_idx', 'prof_dir']]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esdglider",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
